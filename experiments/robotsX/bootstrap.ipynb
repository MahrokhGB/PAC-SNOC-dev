{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] running on CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahrokh/anaconda3/envs/NOC/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.pyplot as plt\n",
    "# import math, itertools\n",
    "import sys, os, pickle, torch\n",
    "\n",
    "BASE_DIR = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "sys.path.insert(1, BASE_DIR)\n",
    "from config import device\n",
    "from assistive_functions import WrapLogger\n",
    "from experiments.robotsX.loss_functions import LossRobots\n",
    "from controllers.SVGD_controller import SVGDCont\n",
    "from experiments.robotsX.detect_collision import *\n",
    "from experiments.robotsX.robots_sys import SystemRobots\n",
    "\n",
    "random_seed = 5\n",
    "random_state = np.random.RandomState(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "logger = WrapLogger(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss saturates at: tensor([[255.8000]])\n"
     ]
    }
   ],
   "source": [
    "# ------ EXPERIMENT ------\n",
    "col_av = True\n",
    "obstacle = True\n",
    "is_linear = False\n",
    "fname = None     # set to None to be set automatically\n",
    "# -----------------------\n",
    "exp_name = 'robotsX'\n",
    "exp_name += '_col_av' if col_av else ''\n",
    "exp_name += '_obstacle' if obstacle else ''\n",
    "exp_name += '_lin' if is_linear else '_nonlin'\n",
    "\n",
    "# ------------ 1. Dataset ------------\n",
    "\n",
    "num_rollouts = 30\n",
    "t_end = 100\n",
    "std_ini = 0.2\n",
    "n_agents = 2\n",
    "file_path = os.path.join(BASE_DIR, 'experiments', 'robotsX', 'saved_results')\n",
    "filename_data = 'data_T'+str(t_end)+'_stdini'+str(std_ini)+'_agents'+str(n_agents)+'_RS'+str(random_seed)+'.pkl'\n",
    "filename_data = os.path.join(file_path, filename_data)\n",
    "if not os.path.isfile(filename_data):\n",
    "    print(filename_data + \" does not exists.\")\n",
    "    print(\"Need to generate data!\")\n",
    "assert os.path.isfile(filename_data)\n",
    "filehandler = open(filename_data, 'rb')\n",
    "data_saved = pickle.load(filehandler)\n",
    "filehandler.close()\n",
    "x0 = data_saved['x0'].to(device)\n",
    "xbar = data_saved['xbar'].to(device)\n",
    "\n",
    "train_data = data_saved['train_data_full'][:num_rollouts, :, :].to(device)\n",
    "assert train_data.shape[0] == num_rollouts\n",
    "test_data = data_saved['test_data'].to(device)\n",
    "\n",
    "# ------------ 2. Parameters and hyperparameters ------------\n",
    "\n",
    "# ------ 2.1. define the plant ------\n",
    "k = 1.0\n",
    "# Set initial values of variables in the loop\n",
    "u_init = None   # all zero\n",
    "x_init = None   # same as xbar\n",
    "sys = SystemRobots(xbar, x_init=x_init, u_init=u_init, k=k, is_linear=is_linear)\n",
    "\n",
    "# ------ 2.2. define the loss ------\n",
    "Q = torch.kron(torch.eye(n_agents), torch.eye(4)).to(device)\n",
    "alpha_u = 0.1/400 if col_av else 1/400\n",
    "alpha_ca = 100 if col_av else None\n",
    "alpha_obst = 5e3 if obstacle else None\n",
    "min_dist = 1.\n",
    "loss_bound = 1\n",
    "sat_bound = torch.matmul(torch.matmul(x0.reshape(1, -1), Q), x0.reshape(-1, 1))\n",
    "sat_bound += 0 if alpha_ca is None else alpha_ca\n",
    "sat_bound += 0 if alpha_obst is None else alpha_obst\n",
    "sat_bound = sat_bound/20\n",
    "logger.info('Loss saturates at: '+str(sat_bound))\n",
    "bounded_loss_fn = LossRobots(\n",
    "    T=t_end, Q=Q, alpha_u=alpha_u, xbar=xbar,\n",
    "    loss_bound=loss_bound, sat_bound=sat_bound.to(device),\n",
    "    alpha_ca=alpha_ca, alpha_obst=alpha_obst,\n",
    "    min_dist=min_dist if col_av else None,\n",
    "    n_agents=sys.n_agents if col_av else None,\n",
    "    num_states=sys.num_states if col_av else None\n",
    ")\n",
    "original_loss_fn = LossRobots(\n",
    "    T=t_end, Q=Q, alpha_u=alpha_u, xbar=xbar,\n",
    "    loss_bound=None, sat_bound=None,\n",
    "    alpha_ca=alpha_ca, alpha_obst=alpha_obst,\n",
    "    min_dist=min_dist if col_av else None,\n",
    "    n_agents=sys.n_agents if col_av else None,\n",
    "    num_states=sys.num_states if col_av else None\n",
    ")\n",
    "\n",
    "# ------ 2.4. define the prior ------\n",
    "prior_std = 7\n",
    "prior_dict = {'type':'Gaussian'}\n",
    "training_param_names = ['X', 'Y', 'B2', 'C2', 'D21', 'D22', 'D12']\n",
    "for name in training_param_names:\n",
    "    prior_dict[name+'_vec_loc'] = 0\n",
    "    prior_dict[name+'_vec_scale'] = prior_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "particles loaded.\n"
     ]
    }
   ],
   "source": [
    "num_particles = 10\n",
    "if fname is not None:\n",
    "    filename = fname+'_particles.pt'\n",
    "else:\n",
    "    filename = exp_name+'_SVGD_'+str(num_particles)+'particles_T'+str(t_end)+'_S'+str(num_rollouts)\n",
    "    filename += '_stdini'+str(std_ini)+'_agents'+str(n_agents)+'_RS'+str(random_seed)+'.pt'\n",
    "file_path = os.path.join(BASE_DIR, 'experiments', 'robotsX', 'saved_results', 'trained_models')\n",
    "filename = os.path.join(file_path, filename)\n",
    "res_dict = torch.load(filename)\n",
    "logger.info('particles loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] initialized particles by sampling from the prior.\n",
      "[INFO] initialized particles by sampling from the prior.\n",
      "Final results on the entire train data: Bounded train loss = 0.1137, original train loss = 29.2211\n",
      "True bounded test loss = 0.1350, true original test loss = 35.70 (approximated using 500 test rollouts).\n"
     ]
    }
   ],
   "source": [
    "particles = res_dict['particles']\n",
    "num_particles = particles.shape[0]\n",
    "\n",
    "# initialize SVGD controllers\n",
    "svgd_cont = SVGDCont(\n",
    "    sys, train_data, \n",
    "    lr=1e-2,                    # not important\n",
    "    loss=bounded_loss_fn,\n",
    "    prior_dict=prior_dict, \n",
    "    initialization_std=res_dict['initialization_std'],    \n",
    "    num_particles=num_particles,\n",
    "    initial_particles=None,     # not important\n",
    "    kernel='RBF', bandwidth=None, random_seed=random_seed,\n",
    "    batch_size=-1,              # not important \n",
    "    lambda_=None,               # not important \n",
    "    num_iter_fit=None,          # not important\n",
    "    lr_decay=0.99, logger=logger, optimizer='Adam',\n",
    "    n_xi=res_dict['n_xi'], l=res_dict['l'], \n",
    "    x_init=sys.x_init, u_init=sys.u_init, \n",
    "    controller_type='REN',\n",
    ")\n",
    "\n",
    "# set particles to the loaded ones\n",
    "svgd_cont.particles = particles\n",
    "    \n",
    "# eval on train data\n",
    "bounded_train_loss = svgd_cont.eval_rollouts(train_data)\n",
    "original_train_loss = svgd_cont.eval_rollouts(train_data, loss_fn=original_loss_fn)\n",
    "logger.info('Final results on the entire train data: Bounded train loss = {:.4f}, original train loss = {:.4f}'.format(\n",
    "    bounded_train_loss, original_train_loss\n",
    "))\n",
    "\n",
    "# eval on test data\n",
    "bounded_test_loss = svgd_cont.eval_rollouts(test_data)\n",
    "original_test_loss = svgd_cont.eval_rollouts(test_data, loss_fn=original_loss_fn)\n",
    "msg = 'True bounded test loss = {:.4f}, '.format(bounded_test_loss)\n",
    "msg += 'true original test loss = {:.2f} '.format(original_test_loss)\n",
    "msg += '(approximated using {:3.0f} test rollouts).'.format(test_data.shape[0])\n",
    "logger.info(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_all_particles = svgd_cont.eval_rollouts(\n",
    "    train_data, loss_fn=original_loss_fn, get_full_list=True\n",
    ")\n",
    "test_loss_all_particles = svgd_cont.eval_rollouts(\n",
    "    test_data, loss_fn=original_loss_fn, get_full_list=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# Bootstrap data\n",
    "repeats = 50\n",
    "data_frac = 0.25\n",
    "num_rollouts_bootstrap = math.floor(data_frac*num_rollouts)\n",
    "data_boot_strap = [None]*repeats\n",
    "for rep_num in range(repeats):\n",
    "    data_boot_strap[rep_num] = np.zeros(\n",
    "        (num_rollouts_bootstrap, train_data.shape[1], train_data.shape[-1])\n",
    "    )\n",
    "    inds = random_state.choice(\n",
    "        range(num_rollouts), size=num_rollouts_bootstrap, replace=True\n",
    "    )\n",
    "    for row_num, ind in enumerate(inds):\n",
    "        data_boot_strap[rep_num][row_num, :, :] = train_data[ind, :, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval on Bootstrap \n",
    "bootstrap_loss_all_particles = np.zeros((repeats, num_particles))\n",
    "for rep_num in range(repeats):\n",
    "    bootstrap_loss_all_particles[rep_num, :] = svgd_cont.eval_rollouts(\n",
    "        data_boot_strap[rep_num], loss_fn=original_loss_fn, get_full_list=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------ format ------\n",
    "plt.rcParams['text.usetex'] = True\n",
    "sns.set_theme(\n",
    "    context='paper', style='whitegrid', palette='bright', \n",
    "    font='sans-serif', font_scale=1.4, color_codes=True, rc=None, \n",
    ")\n",
    "sns.set_style({'grid.linestyle': '--'})\n",
    "mpl.rc('font', family='serif', serif='Times New Roman')\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "ax.boxplot(bootstrap_loss_all_particles)\n",
    "ax.scatter(range(1, num_particles+1), test_loss_all_particles, label='test')\n",
    "ax.scatter(range(1, num_particles+1), train_loss_all_particles, label='train')\n",
    "ax.set_ylabel('original loss')\n",
    "ax.set_xlabel('controller number')\n",
    "ax.set_xlim(0, num_particles+1)\n",
    "    \n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_bounded = test_loss_all_particles\n",
    "train_loss_bounded = train_loss_all_particles\n",
    "boot_loss_bounded = bootstrap_loss_all_particles\n",
    "num_sampled_controllers = num_particles\n",
    "\n",
    "print('Controller Selection Strategies')\n",
    "print('Bootstrap info: repeats = {:.0f}, samples fraction = {:1.2f}'.format(repeats, data_frac)+'\\n')\n",
    "\n",
    "msg = 'test loss of the controller minimizing '\n",
    "print('average test loss of controllers: {:.4f}'.format(sum(test_loss_bounded)/num_sampled_controllers))\n",
    "\n",
    "ind = train_loss_bounded.index(min(train_loss_bounded))\n",
    "# print(ind)\n",
    "print(msg + 'train loss: {:.4f}'.format(test_loss_bounded[ind]))\n",
    "\n",
    "boot_loss_av = np.mean(boot_loss_bounded, axis=0)\n",
    "ind = np.argmin(boot_loss_av)\n",
    "# print(ind)\n",
    "print(msg + 'mean Bootstrap loss: {:.4f}'.format(test_loss_bounded[ind]))\n",
    "\n",
    "boot_loss_quan = np.quantile(boot_loss_bounded, q=3/4, axis=0)\n",
    "ind = np.argmin(boot_loss_quan)\n",
    "# print(ind)\n",
    "print(msg + '3/4 quantile Bootstrap loss: {:.4f}'.format(test_loss_bounded[ind]))\n",
    "\n",
    "boot_loss_std = np.std(boot_loss_bounded, axis=0)\n",
    "ind = np.argmin(boot_loss_av + 1.95*boot_loss_std)\n",
    "# print(ind)\n",
    "print(msg + 'mean+1.95*std Bootstrap loss: {:.4f}'.format(test_loss_bounded[ind]))\n",
    "\n",
    "ind = test_loss_bounded.index(min(test_loss_bounded))\n",
    "# print(ind)\n",
    "print(msg + 'test loss: {:.4f} (ideal)'.format(test_loss_bounded[ind]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.1 ('NOC')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3cea5c68dc0355c09225c58fbb8834b79a134565fb5da138a8afd8fbd1a5df1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
